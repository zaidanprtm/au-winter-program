# -*- coding: utf-8 -*-
"""practice4.ipynb

Automatically generated by Colaboratory.

Original file is located at
"""

# Commented out IPython magic to ensure Python compatibility.
try:
  # %tensorflow_version only exists in Colab.
#   %tensorflow_version 2.x
except Exception:
  pass

import tensorflow as tf
# print(tf.__version__)

#Step 3a: Mount your Google Drive
from google.colab import drive
drive.mount("/content/drive", force_remount=True)

#Step 3b: List the folder
# !ls "/content/drive/My Drive"

# data_path = "  "
# !ls "/content/drive/My Drive/data/"

#alternative data path for local computer
data_path = "/content/drive/My Drive/data/"

import pandas as pd
df_train = pd.read_csv(data_path+ "train.csv")
print(df_train.shape)
# df_train.head()

#limit the amount of training images for the class process
# train_num = df_train.shape[0]
train_num = 480
if train_num >= df_train.shape[0]:
  train_num = df_train.shape[0]
train_files = df_train.iloc[:train_num,0].values
train_labels = df_train.iloc[:train_num,1].values
# print(train_files[:20])
# print(train_labels[:20])

train_path = data_path+ "train_images/"
train_images = []
from tensorflow.keras.preprocessing import image
for file in train_files:
    img = image.load_img(train_path+file, color_mode="rgb")
    train_images.append(img)
    # if len(train_images)%100 == 0:
      # print('.', end='')
# print(len(train_images))

import matplotlib.pyplot as plt
# %matplotlib inline
import random
curclass = 0
fig,ax=plt.subplots(2, 3)
fig.set_size_inches(10,10)
for i in range(2):
    for j in range (3):
        sel=random.randint(0,train_num)
        while train_labels[sel]!=curclass:
          sel +=1
          if sel == train_num -1:
            sel = 0
        curclass += 1
        curclass %= 6
        #sel=random.randint(0,train_num)
        ax[i,j].imshow(train_images[sel], cmap='gray')
        ax[i,j].set_title('No. {} Label:{} '.format(sel, train_labels[sel]))       
# plt.tight_layout()

import numpy as np
labels, counts = np.unique(train_labels, return_counts=True)
# print(labels, counts)

fig = plt.figure(figsize=(8, 5))
plt.bar(labels,counts, width=0.7, align='center')
plt.title("Label Distribution")
plt.xlabel('Label')
plt.ylabel('Count')
plt.xticks(labels)
plt.ylim(0, 120)

for a, b in zip(labels, counts):
    plt.text(a, b, '%d' % b, ha='center', va='bottom', fontsize=10)
# plt.show()

from tensorflow.keras.preprocessing.image import img_to_array
# convert to numpy array
img_array0 = img_to_array(train_images[0])
# print(img_array0.shape)
del img_array0

arr = []
for img in train_images:
    elems = img_to_array(img)
    arr.append(elems)
x_train = np.array(arr)
print(x_train.shape)

# The pixel value in [0,1)
# print(X_train[0, 0 , 0 , 0])

from tensorflow.keras.utils import to_categorical
# one-hot encoding
num_classes = 6
y_train = to_categorical(train_labels,num_classes)
print(y_train.shape)

from tensorflow.keras import Sequential
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Dense, Activation, Flatten
from tensorflow.keras.layers import Input
from tensorflow.keras.layers import Dropout, Flatten, Activation
from tensorflow.keras.layers import Conv2D, MaxPooling2D
from tensorflow.keras.optimizers import Adam,SGD,Adagrad,Adadelta,RMSprop
#create model
model = Sequential()
#add model layers

model.add(Conv2D(filters = 32, kernel_size = (5,5),activation ='relu', input_shape = (512,512,1)))
model.add(MaxPooling2D(pool_size=(2,2)))

model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same',activation ='relu'))
model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))

model.add(Conv2D(filters =96, kernel_size = (3,3),padding = 'Same',activation ='relu'))
model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))

model.add(Flatten())
model.add(Dense(512))
model.add(Activation('relu'))
model.add(Dense(6, activation = "softmax"))
# model.summary()
#compile model using accuracy to measure model performance
# loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)
model.compile(optimizer='adam',loss = None, metrics=['accuracy'])
#train the model
hist = model.fit(x_train,y_train,batch_size=20, epochs=2)
plt.plot(hist.history['accuracy'])
plt.title('Model Accuracy')
plt.ylabel('Accuracy')
plt.xlabel('Epochs')
plt.legend(['train'])
plt.show()
bestprob = []
for i in range(len(x_train)): 
  max = 0
  acc = model.predict(x_train[i].reshape(1,512,512))
  # print(i)
  # print(acc)
  for elems in acc:
  #   maxprob = np.max(elems < 0.9)
  # print(maxprob)
    for elems2 in elems:
      if elems2 < 0.9 and elems2 > max:
        max = elems2  
  result = bestprob.append(max)
print(bestprob)
