# -*- coding: utf-8 -*-
"""practice3.ipynb

Automatically generated by Colaboratory.

Original file is located at
"""

import tensorflow as tf
import numpy as np
mnist = tf.keras.datasets.mnist
(x_train, y_train), (x_test, y_test) = mnist.load_data()
x_train, x_test = x_train / 255.0, x_test / 255.0
# print(x_train.shape)
# print(y_train.shape)
# print(x_test.shape)
# print(y_test.shape)

model = tf.keras.models.Sequential([
tf.keras.layers.Flatten(input_shape=(28, 28)),
tf.keras.layers.Dense(128, activation='relu'),
tf.keras.layers.Dropout(0.2),
tf.keras.layers.Dense(10, activation = 'softmax')
])

loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)
model.compile(optimizer='adam', loss=loss_fn, metrics=['accuracy'])
model.fit(x_train, y_train, epochs=10)
model.evaluate(x_test,  y_test)
bestprob = []
for i in range(len(x_train)): 
  max = 0
  acc = model.predict(x_train[i].reshape(1,28,28))
  # print(i)
  # print(acc)
  for elems in acc:
  #   maxprob = np.max(elems < 0.9)
  # print(maxprob)
    for elems2 in elems:
      if elems2 < 0.9 and elems2 > max:
        max = elems2  
  result = bestprob.append(max)
print(bestprob)